# ЧАВо по лексическому и синтаксическому разборам

# Что из общего почитать по теме?

##  Dick Grune, Ceriel J.H. Jacobs. Parsing Techniques: A Practical Guide (Monographs in Computer Science) 2nd ed. 2008 Edition

_Комментарий от @ksromanov._ Книгу не читал, судя по оглавлению и рекомендациям
уважаемых участников чата Compiler Development в книге представлена достаточно
хорошо структурированная информация для разработки большого класса собственных генераторов
и комбинаторов.

## Шень А. Программирование: теоремы и задачи.

_Комментарий от @ksromanov._ Приятно написанная книга для начинающих: хороший баланс между строгостью и понятностью,
в последних двух главах просто и понятно рассказывается про некоторые типы контекстно-свободных грамматик,
рассказывается про разные методы разбора, в том числе и метод рекурсивного спуска. Фактически, главы 15 и 16
самодостаточны, и являются "дешёвым и сердитым" введением в задачу грамматического (синтаксического) разбора, чтобы понимать
о чём вообще идёт речь и как примерно всё устроено.

# Что почитать по инкрементальному разбору

_пока пусто_

## Чем отличаются лексический и синтаксический разбор?

Очень часто разбор текста и построение из него дерева разбора (_parse tree_) удобно разбить на две фазы. Очень упрощённо, можно сказать, что в первой фазе используется близкая к регулярной (грамматика, описываемая регулярными выражениями), но _не совсем_ регулярная грамматика, что очень важно; а во второй фазе — контекстно-свободная или контекстно-зависимая. Это разбиение, в принципе, не обязательно, но крайне удобно и сильно упрощает задачу.

Первая фаза называется _лексическим_ разбором, а вторая — _синтаксическим_ или _грамматическим_ разбором. Исторически для этих двух фаз часто используются две разные программы с разными языками описания грамматик. Передача потока промежуточных символов (_token_'ов) обычно происходит конвейерным образом (см. конвейер shell, генераторы Python, списки в Haskell) с возможной обратной связью (см. _lexer modes_). Например, связки *lex/yacc* или *Alex/Happy*. Но есть и программы, объединяющие в себе обе фазы с единым конфигурационным файлом, такие как *antlr4* или *BNFC*.

В первой фазе текст пропускается через некоторую программу (_лексер_, сгенерированный *flex* или *Alex*), которая читает текст программы посимвольно (например, UTF8 или ASCII символы), составляя из этих символов слова (так называемые _tokens_) используя конечные автоматы для распознавания регулярных выражений. Грамматика языка, разбираемого лексером отличается от _регулярной_ тем, что в случае альтернативы между _правилами_ выбирается не первый подходящий вариант, а тот, что даёт наиболее длинный префикс (жадный выбор), внутри же _правил_ работает обычная регулярная грамматика. Кроме того, в _лексер_ часто выносятся всевозможные контексто-зависимые хаки (_layout syntax_, _lexer hack_, вырезание комментариев). Важно, что получающееся дерево разбора *вырождено*, то есть, это просто список, и, таким образом, поток символов ASCII/UTF8 превращается в поток _token_'ов. С формальной точки зрения и то, и другое — _символы_, но _разных_ языков.

Во второй фазе поток _token_'ов разбирается уже с помощью _парсера_ контекстно-свободной грамматики (_парсер_, сгенерированный *bison* или *Happy*), превращаясь в обычное дерево разбора. За счёт того, что в этой фазе _символами_ являются _token_'ы, то есть _слова_ первоначального языка, разбор происходит быстрее, а значит упрощается и сам текст грамматики, и уменьшается количество символов, которые подаются на вход программы разбора второй фазы (*парсер*). Это позволяет использовать более _асимптотически сложный_ алгоритм во второй фазе разбора, например со сложностью _O(n^3)_. Также очень важно то, что вынеся различные хаки в _лексер_, во второй фазе разбора, мы можем использовать грамматику относительно простого класса, например контекстно-свободную или даже ещё уже (LR(0), LL(1) и т.д.). Тем не менее, композиция этих двух относительно простых грамматик — _лексера_ и _парсера_ позволяет описывать очень сложные, далеко не контекстно-свободные, грамматики промышленных языков программирования.

Разумеется, эта модель, она упрощена, а в реальной жизни есть и обратная связь между _парсером_ и _лексером_, таким образом, не всегда можно сказать, что промежуточное представление вообще существует, и другие поправки. Обратная связь используется, например, для интерполяции строк, встроенных языков регулярных выражений, сочетаний языков (JavaScript внутри HTML) и т.д.

# Что использовать в качестве генераторов и комбинаторов для разных языков?

## C/C++

1. *flex/bison* — классическая связка генераторов лексического и синтаксического разбора.
Работают с форматами *lex/yacc* соответственно. Не очень удобны для разработки парсеров,
т.к. теряют типы при передаче в основную программу, но зато обладают феноменальной обратной
совместимостью — _написал и забыл_. Можно быть уверенным, что написанная и отлаженная грамматика не потребует
поддержки лет 20.

## OCaml

1. *ocamllex/Menhir* — современная свзяка генераторов лексического и синтаксического разбора.
*Menhir* по всем параметрам превосходит *ocamlyacc*, у него были несовместимые изменения, но давно.

2. *ocamllex/ocamlyacc* — классическая связка генераторов лексического и синтаксического разбора,
аналогичная *flex/bison*, не теряет типы при передаче в основную программу. Аналогично
*flex/bison* поддерживает совместимость. Увы, *ocamlyacc* устарел и постепенно меняется на *Menhir*.

Грамматику, разработанную на *ocamllex/ocamlyacc* очень легко портировать на *flex/bison*, поэтому
OCaml с этой связкой можно использовать для прототипирования.

3. *angstrom* — популярная библиотека комбинаторов.

## Haskell

1. *alex/happy* — связка генераторов, используется в GHC, поэтому можно более-менее надеяться
на стабильность.

2. *parsec* — классическая библиотека комбинаторов. Удобна и проста в использовании.
По её мотивам написаны *megaparsec*, *attoparsec* и пр.

## Языки, основанные на JVM

1. *antlr4* — универсальный инструмент: реализует и лексический, и синтаксический разбор, поддерживает очень широкий спектр возможностей по заданию грамматики и семантических действий, имеет несколько бэкендов для генерации кода на разных языках, может генерировать как традиционную CST + Visitor, так и событийно-ориентированную инфраструктуру, используется в ряде промышленных проектов. [Репозиторий грамматик.](https://github.com/antlr/grammars-v4)
