# ЧАВо по лексическому и синтаксическому разборам

# Что из общего почитать по теме?

##  Dick Grune, Ceriel J.H. Jacobs. Parsing Techniques: A Practical Guide (Monographs in Computer Science) 2nd ed. 2008 Edition

_Комментарий от @ksromanov._ Книгу не читал, судя по оглавлению и рекомендациям
уважаемых участников чата Compiler Development в книге представлена достаточно
хорошо структурированная информация для разработки большого класса собственных генераторов
и комбинаторов.

## Шень А. Программирование: теоремы и задачи.

_Комментарий от @ksromanov._ Приятно написанная книга для начинающих: хороший баланс между строгостью и понятностью,
в последних двух главах просто и понятно рассказывается про некоторые типы контекстно-свободных грамматик,
рассказывается про разные методы разбора, в том числе и метод рекурсивного спуска. Фактически, главы 15 и 16
самодостаточны, и являются "дешёвым и сердитым" введением в задачу грамматического (синтаксического) разбора, чтобы понимать
о чём вообще идёт речь и как примерно всё устроено.

# Что почитать по инкрементальному разбору

_пока пусто_

## Чем отличаются лексический и синтаксический разбор?

Очень часто разбор текста и построение из него дерева разбора (_parse tree_) удобно разбить на две фазы. Очень упрощённо, можно сказать, что в первой фазе используется набор переключаемых грамматик, близких к регулярным (грамматика, описываемая регулярными выражениями); а во второй фазе — контекстно-свободная или контекстно-зависимая. Это разбиение сильно упрощает задачу, позволяя использовать классические _CFG_ парсеры для разбора промышленных языков. В принципе оно не обязательно, поскольку есть альтернативные подходы: PEG, scannerless, парсер-комбинаторы, ручной разбор методом рекурсивного спуска.

Первая фаза называется _лексическим_ разбором, а вторая — _синтаксическим_ или _грамматическим_ разбором. Исторически для этих двух фаз часто используются две разные программы с разными языками описания грамматик. Передача потока промежуточных символов (_token_'ов) обычно происходит конвейерным образом (см. генераторы Python, списки в Haskell) с возможной обратной связью (см. _lexer modes_). Например, связки *lex/yacc* или *Alex/Happy*. Но есть и программы, объединяющие в себе обе фазы с единым конфигурационным файлом, такие как *antlr4* или *BNFC*.

В первой фазе текст пропускается через _лексический анализатор_ или _лексер_ (например, сгенерированный *flex* или *Alex*), который читает текст программы посимвольно (например, UTF8 или ASCII символы) и составляет из этих символов слова (так называемые _tokens_) используя конечные автоматы для распознавания регулярных выражений. В самом простейшем случае, когда есть ровно одно правило, _лексический анализатор_ разбирает язык, грамматика которого очень похожа на регулярную. Её отличие от регулярной заключается в том, что в случае нескольких подходящих _регулярных выражений_ применяется то, что даёт наиболее длинный префикс (жадный выбор `||`), внутри же _регулярных выражений_ работает обычная регулярная грамматика:

```
S → Rule_1
Rule_1 → Pattern_1 || Pattern_2 || ...
Pattern_i → <regexp>
```

Когда правил больше одного, появляется возможность учитывать контекстную зависимость, например комментарии. Важно, что получающееся дерево разбора *вырождено*, то есть, это просто список, и, таким образом, поток символов ASCII/UTF8 превращается в поток _token_'ов. С формальной точки зрения и то, и другое — _символы_, но _разных_ языков.

Во второй фазе поток _token_'ов разбирается уже с помощью _парсера_ контекстно-свободной грамматики (_парсер_, сгенерированный *bison* или *Happy*), превращаясь в обычное дерево разбора. За счёт того, что в этой фазе _символами_ являются _token_'ы, то есть _слова_ первоначального языка, разбор происходит быстрее, а значит упрощается и сам текст грамматики, и уменьшается количество символов, которые подаются на вход _парсера_. Также очень важно то, что вынеся различных контекстно-зависимых нерегулярностей в изначально простую грамматику _лексера_, в _парсере_ мы можем использовать грамматику относительно простого класса, например контекстно-свободную или даже LR(0), LL(1) и т.п. Это в ряде случаев позволяет гарантировать однозначность грамматики _парсера_, её простоту, и высокую скорость _синтаксического разбора_ (почти всегда _O(n)_). Таким образом, грамматики _лексера_ и _парсера_ остаются относительно простыми со всеми сопутствующими выгодами, но в композиции позволяют описывать очень сложные, далеко не контекстно-свободные, грамматики промышленных языков программирования.

Иногда используют обратную связь между _парсером_ и _лексером_ (_lexer mode_), таким образом, не всегда можно сказать, что лексический и синтаксический анализы вообще можно разделить на две фазы разбора. Подобная обратная связь используется, например, для интерполяции строк, встроенных языков регулярных выражений, сочетаний языков (JavaScript внутри HTML) и т.д.

# Что использовать в качестве генераторов и комбинаторов для разных языков?

## C/C++

1. *flex/bison* — классическая связка генераторов лексического и синтаксического разбора.
Работают с форматами *lex/yacc* соответственно. Не очень удобны для разработки парсеров,
т.к. теряют типы при передаче в основную программу, но зато обладают феноменальной обратной
совместимостью — _написал и забыл_. Можно быть уверенным, что написанная и отлаженная грамматика не потребует
поддержки лет 20.

## OCaml

1. *ocamllex/Menhir* — современная свзяка генераторов лексического и синтаксического разбора.
*Menhir* по всем параметрам превосходит *ocamlyacc*, у него были несовместимые изменения, но давно.

2. *ocamllex/ocamlyacc* — классическая связка генераторов лексического и синтаксического разбора,
аналогичная *flex/bison*, не теряет типы при передаче в основную программу. Аналогично
*flex/bison* поддерживает совместимость. Увы, *ocamlyacc* устарел и постепенно меняется на *Menhir*.

Грамматику, разработанную на *ocamllex/ocamlyacc* очень легко портировать на *flex/bison*, поэтому
OCaml с этой связкой можно использовать для прототипирования.

3. *angstrom* — популярная библиотека комбинаторов.

## Haskell

1. *alex/happy* — связка генераторов, используется в GHC, поэтому можно более-менее надеяться
на стабильность.

2. *parsec* — классическая библиотека комбинаторов. Удобна и проста в использовании.
По её мотивам написаны *megaparsec*, *attoparsec* и пр.

## Языки, основанные на JVM

1. *antlr4* — универсальный инструмент: реализует и лексический, и синтаксический разбор, поддерживает очень широкий спектр возможностей по заданию грамматики и семантических действий, имеет несколько бэкендов для генерации кода на разных языках, может генерировать как традиционную CST + Visitor, так и событийно-ориентированную инфраструктуру, используется в ряде промышленных проектов. [Репозиторий грамматик.](https://github.com/antlr/grammars-v4)
